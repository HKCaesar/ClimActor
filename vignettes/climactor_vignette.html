<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Data-Driven Lab" />


<title>The climactor guide</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">The climactor guide</h1>
<h4 class="author">Data-Driven Lab</h4>



<p>As more non-state actors commit to climate action, new initiatives and databases recording such commitments have also become more commonplace. Many actors commit to multiple initiatives and appear in more than one database, yet show up across databases with slightly different names. This discrepancy makes data cleaning and wrangling more difficult than it should be and can result in over-counting of actor’s climate commitments if not dealt with appropriately.</p>
<p>The  package provides a workflow to efficiently standardize actor names across different databases and clean climate commitment data when analyzing non-state actors’ climate commitments.</p>
<div id="data" class="section level2">
<h2>Data</h2>
<p>The data used in this vignette comes from the Carbon Disclosure Project’s 2018-2019 City-wide emissions data. The data can be downloaded <a href="https://data.cdp.net/Emissions/2018-2019-City-wide-emissions/k7qn-m6i9">here</a>. Metadata of the dataset is also documented in the link above.</p>
<p>With data read in (as <code>cdp</code>)</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" title="1"><span class="kw">dim</span>(cdp)</a></code></pre></div>
<pre><code>## [1] 1299   34</code></pre>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1"><span class="co"># Quick peek at the data</span></a>
<a class="sourceLine" id="cb3-2" title="2">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">head</span>(cdp[, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">X.U.FEFF.Year.Reported.to.CDP</th>
<th align="right">Account.Number</th>
<th align="left">Organization</th>
<th align="left">City</th>
<th align="left">Country</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2018</td>
<td align="right">60207</td>
<td align="left">City of Windhoek</td>
<td align="left">Windhoek</td>
<td align="left">Namibia</td>
</tr>
<tr class="even">
<td align="right">2019</td>
<td align="right">60340</td>
<td align="left">Prefeitura de Rio Verde</td>
<td align="left">Rio Verde</td>
<td align="left">Brazil</td>
</tr>
<tr class="odd">
<td align="right">2018</td>
<td align="right">73282</td>
<td align="left">Municipality of Ilha de Mozambique</td>
<td align="left">Ilha</td>
<td align="left">Mozambique</td>
</tr>
<tr class="even">
<td align="right">2019</td>
<td align="right">840313</td>
<td align="left">Municipalidad Cerro Navia</td>
<td align="left"></td>
<td align="left">Chile</td>
</tr>
<tr class="odd">
<td align="right">2018</td>
<td align="right">831231</td>
<td align="left">Kasama Municipal Council</td>
<td align="left">Kasama</td>
<td align="left">Zambia</td>
</tr>
<tr class="even">
<td align="right">2018</td>
<td align="right">59697</td>
<td align="left">City of Lake Worth, FL</td>
<td align="left">Lake Worth</td>
<td align="left">United States of America</td>
</tr>
</tbody>
</table>
<p>Apart from the data you wish to clean, two other important datasets would be the key dictionary (<code>key_dict</code>) and country dictionary (<code>country_dict</code>). These datasets can be accessed once the <code>climactor</code> package has been called with either <code>library(climactor)</code> or <code>require(climactor)</code>. For more details on the two dictionaries, you can use <code>?key_dict</code> and <code>?country_dict</code> for the full data documentation.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">head</span>(key_dict[, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">right</th>
<th align="left">wrong</th>
<th align="left">iso</th>
<th align="left">entity.type</th>
<th align="left">allcaps</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Lassee</td>
<td align="left">Lassee</td>
<td align="left">AUT</td>
<td align="left">City</td>
<td align="left">LASSEE</td>
</tr>
<tr class="even">
<td align="left">Laxenburg</td>
<td align="left">Laxenburg</td>
<td align="left">AUT</td>
<td align="left">City</td>
<td align="left">LAXENBURG</td>
</tr>
<tr class="odd">
<td align="left">Antwerp</td>
<td align="left">Antwerp</td>
<td align="left">BEL</td>
<td align="left">City</td>
<td align="left">ANTWERP</td>
</tr>
<tr class="even">
<td align="left">Bruxelles-Capitale</td>
<td align="left">Bruxelles-Capitale</td>
<td align="left">BEL</td>
<td align="left">City</td>
<td align="left">BRUXELLES-CAPITALE</td>
</tr>
<tr class="odd">
<td align="left">Genk</td>
<td align="left">Genk</td>
<td align="left">BEL</td>
<td align="left">City</td>
<td align="left">GENK</td>
</tr>
<tr class="even">
<td align="left">Ghent</td>
<td align="left">Gent</td>
<td align="left">BEL</td>
<td align="left">City</td>
<td align="left">GENT</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">knitr<span class="op">::</span><span class="kw">kable</span>(<span class="kw">head</span>(country_dict[, <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]))</a></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">wrong</th>
<th align="left">right</th>
<th align="right">code</th>
<th align="left">iso</th>
<th align="left">region</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Guinea Bissau</td>
<td align="left">Guinea-Bissau</td>
<td align="right">624</td>
<td align="left">GNB</td>
<td align="left">Sub-Saharan Africa</td>
</tr>
<tr class="even">
<td align="left">Afghanistan</td>
<td align="left">Afghanistan</td>
<td align="right">4</td>
<td align="left">AFG</td>
<td align="left">South Asia</td>
</tr>
<tr class="odd">
<td align="left">Albania</td>
<td align="left">Albania</td>
<td align="right">8</td>
<td align="left">ALB</td>
<td align="left">Eastern Europe and Central Asia</td>
</tr>
<tr class="even">
<td align="left">Algeria</td>
<td align="left">Algeria</td>
<td align="right">12</td>
<td align="left">DZA</td>
<td align="left">Middle East and North Africa</td>
</tr>
<tr class="odd">
<td align="left">American Samoa</td>
<td align="left">American Samoa</td>
<td align="right">16</td>
<td align="left">ASM</td>
<td align="left">East Asia and the Pacific</td>
</tr>
<tr class="even">
<td align="left">Andorra</td>
<td align="left">Andorra</td>
<td align="right">20</td>
<td align="left">AND</td>
<td align="left">Europe</td>
</tr>
</tbody>
</table>
</div>
<div id="data-preparation-functions" class="section level2">
<h2>Data Preparation functions</h2>
<p>Naturally, the first step in any data cleaning pipeline would be to read in and prepare the data.</p>
<p>Within the <code>climactor</code> workflow the first important step comes when the data is read in. For the later string matching aspects of the workflow to work more accurately, the data should ideally be read in or converted to <strong>UTF-8</strong> encoding. <strong>UTF-8</strong> is the preferred encoding when working with strings and both the <code>key_dict</code> and <code>country_dict</code> are encoding in UTF-8 encoding. Reading in data with the UTF-8 encoding can be done by using the <code>encoding</code> argument within the <code>read.csv</code> function.</p>
<p>If you know the encoding of your data, it is best to convert it to UTF-8 (either within R or elsewhere) before proceeding with the string matching algorithmns. If you are unsure of the encoding of your data, it is more important to read the data into R in its correct native encoding rather than to try and force the wrong encoding (eg. reading in data as UTF-8 when the data is encoded in Latin1). For those which are unfamiliar with encoding issues, an (optional) helper function within some string matching functions will try to guess the encoding of your data and fix it. For more information on the helper function, see the code in the github <a href="https://github.com/datadrivenyale/climactor/blob/master/R/helper_functions.R">here</a>.</p>
<p>If you would like to learn more about encoding in R, you can refer to the Appendix (<em>Notes on encoding</em>) of this vignette or refer to several articles writtin on the topic by <a href="http://kunststube.net/encoding">Kunsttube</a>, <a href="http://kevinushey.github.io/">Kevin Ushey</a>, or <a href="https://rstudio-pubs-static.s3.amazonaws.com/279354_f552c4c41852439f910ad620763960b6.html">Maurício Collaça</a>.</p>
<p>3 specific variables (name, country, entity type) are the most important while using the <code>climactor</code> package. Data preparation functions ensure that these variables are present and include the following functions:</p>
<ul>
<li><code>rename_col()</code> to rename data columns to the appropriate names</li>
<li><code>add_country()</code> adds the country column to the dataset</li>
<li><code>add_entity_type()</code> adds the entity type column to the dataset</li>
<li><code>add_country_entity_type()</code> adds both the country and entity type columns to the dataset</li>
</ul>
<div id="rename-columns-with-rename_col" class="section level3">
<h3>Rename columns with <code>rename_col()</code></h3>
<p><code>rename_col()</code> checks the dataset for the requisite names and asks the user for columns to be renamed if the dataset do not contain the requisite names. This function ensures that column names are standardized so that downstream functions will work as intended. The only argument for the function is the user’s dataset that is to be cleaned.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># Check before </span></a>
<a class="sourceLine" id="cb6-2" title="2"><span class="kw">names</span>(cdp)[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]</a></code></pre></div>
<pre><code>## [1] &quot;X.U.FEFF.Year.Reported.to.CDP&quot; &quot;Account.Number&quot;               
## [3] &quot;Organization&quot;                  &quot;City&quot;                         
## [5] &quot;Country&quot;</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">rename_col</span>(cdp)</a></code></pre></div>
<pre><code>Please input the column name that contains the actors&#39; names. 
Input &quot;skip&quot; if column does not exist.</code></pre>
<pre><code>Input:Organization</code></pre>
<pre><code>Please input the column name that contains the actors&#39; entity types.
Input &quot;skip&quot; if column does not exist.</code></pre>
<pre><code>Input:skip</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" title="1"><span class="co"># Check names after</span></a>
<a class="sourceLine" id="cb13-2" title="2"><span class="kw">names</span>(cdp)[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]</a></code></pre></div>
<pre><code>## [1] &quot;X.U.FEFF.Year.Reported.to.CDP&quot; &quot;Account.Number&quot;               
## [3] &quot;name&quot;                          &quot;City&quot;                         
## [5] &quot;Country&quot;</code></pre>
</div>
<div id="add-country-column-with-add_country" class="section level3">
<h3>Add country column with <code>add_country()</code></h3>
<p><code>add_country()</code> first checks the dataset for the country column within the dataset provided. If the dataset does not contain a country column, then a country column will be initialized with default <code>NA</code> values. In this case, the country already exists in the cdp dataset.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">add_country</span>(cdp)</a></code></pre></div>
<pre><code>## A &quot;country&quot; column already exists in the dataset.</code></pre>
</div>
<div id="add-the-entity-type-column-with-add_entity_type" class="section level3">
<h3>Add the entity type column with <code>add_entity_type()</code></h3>
<p><code>add_entity_type()</code> first checks the dataset for the entity type column within the dataset provided. If the dataset does not contain and entity type column, then an entity type column will be initiatlized with a user specified input. In this case, we set the input as “City”, since a majority of the actors within the CDP dataset are cities.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">add_entity_type</span>(cdp, <span class="st">&quot;City&quot;</span>)</a>
<a class="sourceLine" id="cb17-2" title="2"><span class="co"># Check the last few columns of the dataset</span></a>
<a class="sourceLine" id="cb17-3" title="3"><span class="kw">head</span>(cdp[, (<span class="kw">ncol</span>(cdp)<span class="op">-</span><span class="dv">5</span>)<span class="op">:</span><span class="kw">ncol</span>(cdp)])</a></code></pre></div>
<pre><code>##   Population Population.Year             City.Location
## 1     322500            2011  POINT (17.0658 -22.5609)
## 2     229651            2018 POINT (-50.4892 -17.9685)
## 3         NA               0 POINT (-40.7323 -15.0364)
## 4     132622            2017                          
## 5     350000            2010  POINT (31.1808 -10.2129)
## 6      36000            2017  POINT (-80.0684 26.6168)
##   Water.2014...Number.of.drivers             Last.update entity.type
## 1                             NA 2019-12-17T09:03:41.637        City
## 2                            213 2019-12-17T09:03:43.757        City
## 3                             NA 2019-12-17T09:03:41.637        City
## 4                             NA 2019-12-17T09:03:43.757        City
## 5                            156 2019-12-17T09:03:41.637        City
## 6                             NA 2019-12-17T09:03:41.637        City</code></pre>
</div>
<div id="add-both-country-and-entity-type-columns-to-the-dataset-with-add_country_entity_type" class="section level3">
<h3>Add both country and entity type columns to the dataset with <code>add_country_entity_type()</code></h3>
<p><code>add_country_entity_type()</code> constitutes a combination of the above two functions, and should be used if users know both country and entity type columns are missing from the dataset. Similarly, the function checks the dataset for both of these columns and does not add new columns if the columns are found within the dataset. If not, a country column is defined with default <code>NA</code> values, and an entity type column is defined with values from the <code>type</code> argument. In this case, both countries are already present in the cdp database and thus the function does not add any new columns.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" title="1"><span class="kw">ncol</span>(cdp)</a></code></pre></div>
<pre><code>## [1] 35</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">add_country_entity_type</span>(cdp)</a></code></pre></div>
<pre><code>## A &quot;country&quot; already exists in the dataset.
## A &quot;entity type&quot; already exists in the dataset.</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" title="1"><span class="kw">ncol</span>(cdp)</a></code></pre></div>
<pre><code>## [1] 35</code></pre>
</div>
</div>
<div id="standardizing-and-preprocessing-of-data" class="section level2">
<h2>Standardizing and preprocessing of data</h2>
<p>After the preliminary preparation of data from the previous functions, we now move on to functions that start standardizing and preprocess the dataset from the user. This family of functions provide easy ways to further standardize the structure of your data and to make inferences based on your dataset that will help with steps in cleaning and matching your dataset to the key dictionaries in later functions.</p>
<div id="fill-in-entity-types-for-your-data-using-fill_type" class="section level3">
<h3>Fill in entity types for your data using <code>fill_type()</code></h3>
<p>Since the <code>add_entity_type()</code> function only allow users to input only one entity type for the entire dataset, the <code>fill_type()</code> function will allow users to update the entity type for users with datasets that contain more than one entity type. The function looks at the actor name and identifies common words within the actor’s name to guess the entity type for that actor.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" title="1"><span class="kw">table</span>(cdp<span class="op">$</span>entity.type)</a></code></pre></div>
<pre><code>## 
## City 
## 1299</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">fill_type</span>(cdp)</a></code></pre></div>
<pre><code>## Warning: This function will be generally accurate for the entity type of most--but not all--entries. It is highly recommended you double check the entity types, fix any errors, and fill in any missing values.</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" title="1"><span class="kw">table</span>(cdp<span class="op">$</span>entity.type)</a></code></pre></div>
<pre><code>## 
##    City Company  Region 
##    1087       2     210</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" title="1"><span class="co"># Just do a quick check for the ones listed as company</span></a>
<a class="sourceLine" id="cb31-2" title="2">cdp<span class="op">$</span>name[<span class="kw">which</span>(cdp<span class="op">$</span>entity.type <span class="op">==</span><span class="st"> &quot;Company&quot;</span>)]</a></code></pre></div>
<pre><code>## [1] &quot;Corporation of Chennai&quot; &quot;Corporation of Chennai&quot;</code></pre>
<p>The example here highlights the importance to conduct careful checks on the data after using the <code>fill_type()</code> function. The function picked up two actors which has the word “Corporation” in its name, but should really be cities (instead of companies). We manually fix the entity types for these actors.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" title="1">cdp<span class="op">$</span>entity.type[<span class="kw">which</span>(cdp<span class="op">$</span>entity.type <span class="op">==</span><span class="st"> &quot;Company&quot;</span>)] &lt;-<span class="st"> &quot;City&quot;</span></a></code></pre></div>
</div>
<div id="remove-fill-words-from-actor-names-using-remove_extra" class="section level3">
<h3>Remove fill words from actor names using <code>remove_extra()</code></h3>
<p>The <code>remove_extra()</code> function removes extraneous words from the actors’ names such as “Council”, “District”, “Province”, etc etc. This helps to streamline the matching process used in downstream functions and provides better matches with the key dictionary. However, some of these words are used in the <code>fill_type()</code> function to determine the entity type of the actor, hence it is recommended that the <code>remove_extra()</code> function be used after the <code>fill_type()</code> function.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" title="1"><span class="co"># Make a copy of the original names </span></a>
<a class="sourceLine" id="cb34-2" title="2">orignames &lt;-<span class="st"> </span>cdp<span class="op">$</span>name</a>
<a class="sourceLine" id="cb34-3" title="3"></a>
<a class="sourceLine" id="cb34-4" title="4"><span class="co"># Apply remove_extra function</span></a>
<a class="sourceLine" id="cb34-5" title="5">cdp &lt;-<span class="st"> </span><span class="kw">remove_extra</span>(cdp)</a>
<a class="sourceLine" id="cb34-6" title="6"></a>
<a class="sourceLine" id="cb34-7" title="7"><span class="co"># Check for differences </span></a>
<a class="sourceLine" id="cb34-8" title="8"><span class="kw">length</span>(<span class="kw">setdiff</span>(orignames, cdp<span class="op">$</span>name))</a></code></pre></div>
<pre><code>## [1] 632</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" title="1"><span class="co"># 632 differences </span></a>
<a class="sourceLine" id="cb36-2" title="2"></a>
<a class="sourceLine" id="cb36-3" title="3"><span class="co"># For comparison&#39;s sake, look at some of the differences </span></a>
<a class="sourceLine" id="cb36-4" title="4"><span class="kw">head</span>(orignames[<span class="op">!</span>orignames <span class="op">%in%</span><span class="st"> </span>cdp<span class="op">$</span>name])</a></code></pre></div>
<pre><code>## [1] &quot;City of Windhoek&quot;                   &quot;Municipality of Ilha de Mozambique&quot;
## [3] &quot;Municipalidad Cerro Navia&quot;          &quot;Kasama Municipal Council&quot;          
## [5] &quot;City of Lake Worth, FL&quot;             &quot;City of Winona, MN&quot;</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" title="1"><span class="kw">head</span>(cdp<span class="op">$</span>name[<span class="op">!</span>cdp<span class="op">$</span>name <span class="op">%in%</span><span class="st"> </span>orignames])</a></code></pre></div>
<pre><code>## [1] &quot;Windhoek&quot;           &quot;Ilha de Mozambique&quot; &quot;Cerro Navia&quot;       
## [4] &quot;Kasama&quot;             &quot;Lake Worth, FL&quot;     &quot;Winona, MN&quot;</code></pre>
</div>
<div id="clean-country-names-and-add-iso-data-using-clean_country_iso" class="section level3">
<h3>Clean country names and add ISO data using <code>clean_country_iso()</code></h3>
<p><code>clean_country_iso()</code> checks the countries in the supplied dataset and a supplied country dictionary using direct string matching and cleans the country names according to the standardized version in the country dictionary. The function allows users to input their own country dictionary (in the event that the user has a locally updated country dictionary, or their own one) but the package’s included country dictionary can be called using <code>country_dict</code>. ISO2 and ISO3 data is available for including in one’s own dataset, with users being able to select which version they prefer (with ISO3 being the default). Lastly, <code>clean_enc = F</code> checks the encoding of the country column of the user’s dataset, guesses the correct encoding of the data, and tries to repair it if the data was read in with the wrong encoding. The default for this argument is <code>T</code> (checks not conducted), but the user should set it to <code>F</code> if they are unsure if they have read in the data in the correct encoding. A tell-tale sign is usually when unrecognized symbols or accents appear in the country names of the dataset.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" title="1"><span class="co"># Set clean_enc = F (not sure if encoding is &quot;clean&quot; for the sake of this example)</span></a>
<a class="sourceLine" id="cb40-2" title="2"><span class="co"># Use package&#39;s country dictionary</span></a>
<a class="sourceLine" id="cb40-3" title="3"><span class="co"># As usual, we store an original copy of the country names for comparison later on</span></a>
<a class="sourceLine" id="cb40-4" title="4">origcountry &lt;-<span class="st"> </span>cdp<span class="op">$</span>Country</a>
<a class="sourceLine" id="cb40-5" title="5">cdp &lt;-<span class="st"> </span><span class="kw">clean_country_iso</span>(cdp, country_dict, <span class="dt">iso =</span> <span class="dv">3</span>, <span class="dt">clean_enc =</span> F)</a></code></pre></div>
<pre><code>## Best guess: UTF-8 (100% confident)</code></pre>
<pre><code>## Best guess: windows-1250 (57% confident)</code></pre>
<pre><code>## [1] &quot;There are 21 entries with no exact matches in the country dictionary. The indices for these names are recorded in the country_ind vector Please use the fuzzify_country function to clean those names or input them manually.&quot;</code></pre>
<p>We see that there are 21 countries in the cdp dataset that do not have an exact match in the country dictionary. The <code>country_ind</code> vector was created to show which rows in the datasets have countries where there was no exact matches in the country_dictionary. Let’s examine these countries using the <code>country_ind</code> vector.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb44-1" title="1">cdp<span class="op">$</span>Country[country_ind]</a></code></pre></div>
<pre><code>##  [1] &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot; NA                     
##  [4] &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot;
##  [7] NA                      &quot;Taiwan, Greater China&quot; NA                     
## [10] NA                      &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot;
## [13] &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot;
## [16] &quot;Taiwan, Greater China&quot; NA                      &quot;Taiwan, Greater China&quot;
## [19] &quot;Taiwan, Greater China&quot; &quot;Taiwan, Greater China&quot; NA</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" title="1"><span class="co"># seems like there are some NAs in the data </span></a></code></pre></div>
<p>It seems like there are some NAs in the data. Apart from that, the only other country where there isn’t an exact match is Taiwan. These names will be matched in a later function, as detailed below.</p>
</div>
</div>
<div id="stringphonetic-matching-functions-and-cleaning-of-actor-names" class="section level2">
<h2>String/Phonetic matching functions and cleaning of actor names</h2>
<p>We now almost have all that we need to start the process of cleaning actors’ names in the dataset (the primary goal of the package). To do that, we first need to start with making sure all the country names in our dataset are standardized. This picks up from the previous section where we used exact string matching to clean the country names within the dataset. Now, we use fuzzy string matching to standardize and clean whatever country names are left to be cleaned. Then, the functions following which will attempt to clean the actors’ names first through exact matching, then through phonetic string matching.</p>
<div id="use-fuzzify_country-to-ensure-all-countries-in-dataset-are-cleaned" class="section level3">
<h3>Use <code>fuzzify_country()</code> to ensure all countries in dataset are cleaned</h3>
<p>This function is a continuation of the previous function <code>clean_country_iso()</code>, and should only be used 1) after the <code>clean_country_iso()</code> function has been used and 2) if there are any remaining countries that need to be cleaned (signaled by the presence of a <code>country_ind</code> vector). The function makes use of base R fuzzy matching algorithms to detect similar country names within the country dictionary to match to the user’s input. The base R function in turn makes use of the Levenshtein distance to implement the fuzzy matching. The function will only do fuzzy matching for the rows which are in the <code>country_ind</code> vector, hence making the use of the <code>clean_country_iso()</code> function prior to the <code>fuzzify_country()</code> function crucial.</p>
<p>The <code>fuzzify_country()</code> function also returns different vectors based on the different input specified by the user. A <code>custom_count</code> vector will be returned if users decided to input a custom country for any actors. An <code>unmatched_count</code> vector will be returned if users decided to skip any countries within their dataset, such that they can return to it later or input their own countries later on.<br />
It should also be further noted that the <code>fuzzify_country()</code> function will not match for <code>NA</code> values in the country column. The indices for these countries will still remain in the <code>country_ind</code> vector for users to easily check the name and entity types of those actors. The reason for this is to encourage users to manually check for those actors which countries are <code>NA</code> to ensure that these entries are valid. Users can opt to manually input a country after checking before using the functions to standardize the country names.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" title="1">cdp &lt;-<span class="st"> </span><span class="kw">fuzzify_country</span>(cdp, country_dict)</a></code></pre></div>
<pre><code>[1] &quot;The original country is Taiwan, Greater China (Actor name: Yilan)&quot;
[1] &quot;Here are some possible matches we found: &quot;
1. Taiwan
 2. Macao
 3. Macao
 4. China
 5. Hong Kong
 6. Saint Helena
 7. Saint Martin
 8. Saint Martin
 9. Hong Kong
 10. Taiwan
 11. Papua New Guinea
 12. Saint Martin
 13. San Marino
 14. Bosnia and Herzegovina
 15. Bosnia and Herzegovina
Which name matches? Choose 1-15. (Type N if none match; type S to save your current progress)</code></pre>
<pre><code>Answer: 1</code></pre>
<pre><code>[1] &quot;Taiwan has been selected and will replace Taiwan, Greater China in the database.&quot;</code></pre>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
