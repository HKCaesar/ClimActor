---
title: "The climactor guide"
author: "Data-Driven Lab"
output: rmarkdown::html_vignette
params:
  cdpname: name
vignette: >
  %\VignetteIndexEntry{The climactor guide}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(climactor)
```

As more non-state actors commit to climate action, new initiatives and databases recording such commitments have also become more commonplace. Many actors commit to multiple initiatives and appear in more than one database, yet show up across databases with slightly different names. This discrepancy makes data cleaning and wrangling more difficult than it should be and can result in over-counting of actor's climate commitments if not dealt with appropriately. 

The \code{climactor} package provides a workflow to efficiently standardize actor names across different databases and clean climate commitment data when analyzing non-state actors' climate commitments. 

## Data

The data used in this vignette comes from the Carbon Disclosure Project's 2018-2019 City-wide emissions data. The data can be downloaded [here](https://data.cdp.net/Emissions/2018-2019-City-wide-emissions/k7qn-m6i9). Metadata of the dataset is also documented in the link above. 

```{r, include = FALSE}
cdp <- read.csv("../data-raw/2018_-_2019_City-wide_emissions.csv", stringsAsFactors = F,
                as.is = T, encoding = "UTF-8")
```

With data read in (as `cdp`)

``` {r}
dim(cdp)

# Quick peek at the data
knitr::kable(head(cdp[, 1:5]))
```

Apart from the data you wish to clean, two other important datasets would be the key dictionary (`key_dict`) and country dictionary (`country_dict`). These datasets can be accessed once the `climactor` package has been called with either `library(climactor)` or `require(climactor)`. For more details on the two dictionaries, you can use `?key_dict` and `?country_dict` for the full data documentation.  

```{r}
knitr::kable(head(key_dict[, 1:5]))
knitr::kable(head(country_dict[, 1:5]))
```

## Data Preparation functions

Naturally, the first step in any data cleaning pipeline would be to read in and prepare the data.

Within the `climactor` workflow the first important step comes when the data is read in. For the later string matching aspects of the workflow to work more accurately, the data should ideally be read in or converted to **UTF-8** encoding. **UTF-8** is the preferred encoding when working with strings and both the `key_dict` and `country_dict` are encoding in UTF-8 encoding. Reading in data with the UTF-8 encoding can be done by using the `encoding` argument within the `read.csv` function. 

If you know the encoding of your data, it is best to convert it to UTF-8 (either within R or elsewhere) before proceeding with the string matching algorithmns. If you are unsure of the encoding of your data, it is more important to read the data into R in its correct native encoding rather than to try and force the wrong encoding (eg. reading in data as UTF-8 when the data is encoded in Latin1). For those which are unfamiliar with encoding issues, an (optional) helper function within some string matching functions will try to guess the encoding of your data and fix it. For more information on the helper function, see the code in the github [here](https://github.com/datadrivenyale/climactor/blob/master/R/helper_functions.R). 

If you would like to learn more about encoding in R, you can refer to the Appendix (*Notes on encoding*) of this vignette or refer to several articles writtin on the topic by [Kunsttube](http://kunststube.net/encoding), [Kevin Ushey](http://kevinushey.github.io/), or [Maurício Collaça](https://rstudio-pubs-static.s3.amazonaws.com/279354_f552c4c41852439f910ad620763960b6.html). 

3 specific variables (name, country, entity type) are the most important while using the `climactor` package. Data preparation functions ensure that these variables are present and include the following functions: 

* `rename_col()` to rename data columns to the appropriate names 
* `add_country()` adds the country column to the dataset
* `add_entity_type()` adds the entity type column to the dataset
* `add_country_entity_type()` adds both the country and entity type columns to the dataset


### Rename columns with `rename_col()`

`rename_col()` checks the dataset for the requisite names and asks the user for columns to be renamed if the dataset do not contain the requisite names. This function ensures that column names are standardized so that downstream functions will work as intended. The only argument for the function is the user's dataset that is to be cleaned. 

```{r}
# Check before 
names(cdp)[1:5]
```

```{r, eval = F}
cdp <- rename_col(cdp)

```
```{r, echo = F, comment = ""}
# Note that because R Markdown does not really support interactive input, the 
# output that a user can expect for this dataset is printed here for user's reference 
cat("Please input the column name that contains the actors' names. \nInput \"skip\" if column does not exist.")
cat("Input:Organization")

cat("Please input the column name that contains the actors' entity types.\nInput \"skip\" if column does not exist.")
cat("Input:skip")

names(cdp)[grep("Organization", names(cdp))] <- "name"
```
```{r}
# Check names after
names(cdp)[1:5]
```

### Add country column with `add_country()`
`add_country()` first checks the dataset for the country column within the dataset provided. If the dataset does not contain a country column, then a country column will be initialized with default `NA` values. In this case, the country already exists in the cdp dataset. 
```{r, error = T}
cdp <- add_country(cdp)

```

### Add the entity type column with `add_entity_type()`
`add_entity_type()` first checks the dataset for the entity type column within the dataset provided. If the dataset does not contain and entity type column, then an entity type column will be initiatlized with a user specified input. In this case, we set the input as "City", since a majority of the actors within the CDP dataset are cities. 
```{r}
cdp <- add_entity_type(cdp, "City")
# Check the last few columns of the dataset
head(cdp[, (ncol(cdp)-5):ncol(cdp)])
```
### Add both country and entity type columns to the dataset with `add_country_entity_type()`
`add_country_entity_type()` constitutes a combination of the above two functions, and should be used if users know both country and entity type columns are missing from the dataset. Similarly, the function checks the dataset for both of these columns and does not add new columns if the columns are found within the dataset. If not, a country column is defined with default `NA` values, and an entity type column is defined with values from the `type` argument. In this case, both countries are already present in the cdp database and thus the function does not add any new columns. 
```{r}
ncol(cdp)
cdp <- add_country_entity_type(cdp)
ncol(cdp)
```

## Standardizing and preprocessing of data
After the preliminary preparation of data from the previous functions, we now move on to functions that start standardizing and preprocess the dataset from the user. This family of functions provide easy ways to further standardize the structure of your data and to make inferences based on your dataset that will help with steps in cleaning and matching your dataset to the key dictionaries in later functions.

### Fill in entity types for your data using `fill_type()`
Since the `add_entity_type()` function only allow users to input only one entity type for the entire dataset, the `fill_type()` function will allow users to update the entity type for users with datasets that contain more than one entity type. The function looks at the actor name and identifies common words within the actor's name to guess the entity type for that actor. 
```{r}
table(cdp$entity.type)
cdp <- fill_type(cdp)
table(cdp$entity.type)
# Just do a quick check for the ones listed as company
cdp$name[which(cdp$entity.type == "Company")]
```
The example here highlights the importance to conduct careful checks on the data after using the `fill_type()` function. The function picked up two actors which has the word "Corporation" in its name, but should really be cities (instead of companies). We manually fix the entity types for these actors. 
```{r}
cdp$entity.type[which(cdp$entity.type == "Company")] <- "City"
```

### Remove fill words from actor names using `remove_extra()`
The `remove_extra()` function removes extraneous words from the actors' names such as "Council", "District", "Province", etc etc. This helps to streamline the matching process used in downstream functions and provides better matches with the key dictionary. However, some of these words are used in the `fill_type()` function to determine the entity type of the actor, hence it is recommended that the `remove_extra()` function be used after the `fill_type()` function. 

```{r}
# Make a copy of the original names 
orignames <- cdp$name

# Apply remove_extra function
cdp <- remove_extra(cdp)

# Check for differences 
length(setdiff(orignames, cdp$name))
# 632 differences 

# For comparison's sake, look at some of the differences 
head(orignames[!orignames %in% cdp$name])
head(cdp$name[!cdp$name %in% orignames])

```

### Clean country names and add ISO data using `clean_country_iso()`
`clean_country_iso()` checks the countries in the supplied dataset and a supplied country dictionary using direct string matching and cleans the country names according to the standardized version in the country dictionary. The function allows users to input their own country dictionary (in the event that the user has a locally updated country dictionary, or their own one) but the package's included country dictionary can be called using `country_dict`. ISO2 and ISO3 data is available for including in one's own dataset, with users being able to select which version they prefer (with ISO3 being the default). Lastly, `clean_enc = F` checks the encoding of the country column of the user's dataset, guesses the correct encoding of the data, and tries to repair it if the data was read in with the wrong encoding. The default for this argument is `T` (checks not conducted), but the user should set it to `F` if they are unsure if they have read in the data in the correct encoding. A tell-tale sign is usually when unrecognized symbols or accents appear in the country names of the dataset. 

```{r}
# Set clean_enc = F (not sure if encoding is "clean" for the sake of this example)
# Use package's country dictionary
# As usual, we store an original copy of the country names for comparison later on
origcountry <- cdp$Country
cdp <- clean_country_iso(cdp, country_dict, iso = 3, clean_enc = F)

```
We see that there are 21 countries in the cdp dataset that do not have an exact match in the country dictionary. Let's examine these countries using the `country_ind` vector that was created from the function. 

```{r}
cdp$country
```

